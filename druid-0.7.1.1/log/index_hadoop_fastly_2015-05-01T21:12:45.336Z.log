2015-05-01T21:12:47,104 INFO [main] io.druid.guice.PropertiesModule - Loading properties from common.runtime.properties
2015-05-01T21:12:47,113 INFO [main] io.druid.guice.PropertiesModule - Loading properties from runtime.properties
May 01, 2015 9:12:47 PM org.hibernate.validator.internal.util.Version <clinit>
INFO: HV000001: Hibernate Validator 5.1.3.Final
2015-05-01T21:12:48,354 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.guice.ExtensionsConfig] from props[druid.extensions.] as [ExtensionsConfig{searchCurrentClassloader=true, coordinates=[io.druid.extensions:druid-examples, io.druid.extensions:druid-kafka-eight, io.druid.extensions:mysql-metadata-storage, io.druid.extensions:druid-hdfs-storage], defaultVersion='0.7.1.1', localRepository='/root/.m2/repository', remoteRepositories=[https://repo1.maven.org/maven2/, https://metamx.artifactoryonline.com/metamx/pub-libs-releases-local]}]
2015-05-01T21:12:48,756 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-examples] for class[io.druid.cli.CliCommandCreator]
2015-05-01T21:12:50,878 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/druid-examples/0.7.1.1/druid-examples-0.7.1.1.jar]
2015-05-01T21:12:50,878 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/twitter4j/twitter4j-core/3.0.3/twitter4j-core-3.0.3.jar]
2015-05-01T21:12:50,878 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/twitter4j/twitter4j-async/3.0.3/twitter4j-async-3.0.3.jar]
2015-05-01T21:12:50,878 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/twitter4j/twitter4j-stream/3.0.3/twitter4j-stream-3.0.3.jar]
2015-05-01T21:12:50,879 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-validator/commons-validator/1.4.0/commons-validator-1.4.0.jar]
2015-05-01T21:12:50,879 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils/1.8.3/commons-beanutils-1.8.3.jar]
2015-05-01T21:12:50,879 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar]
2015-05-01T21:12:50,879 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar]
2015-05-01T21:12:50,895 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-kafka-eight] for class[io.druid.cli.CliCommandCreator]
2015-05-01T21:12:51,181 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/druid-kafka-eight/0.7.1.1/druid-kafka-eight-0.7.1.1.jar]
2015-05-01T21:12:51,197 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar]
2015-05-01T21:12:51,197 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar]
2015-05-01T21:12:51,197 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar]
2015-05-01T21:12:51,197 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.1/kafka-clients-0.8.2.1.jar]
2015-05-01T21:12:51,197 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar]
2015-05-01T21:12:51,197 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.6/snappy-java-1.1.1.6.jar]
2015-05-01T21:12:51,198 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar]
2015-05-01T21:12:51,198 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar]
2015-05-01T21:12:51,198 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/log4j/log4j/1.2.16/log4j-1.2.16.jar]
2015-05-01T21:12:51,198 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar]
2015-05-01T21:12:51,198 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar]
2015-05-01T21:12:51,198 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar]
2015-05-01T21:12:51,198 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar]
2015-05-01T21:12:51,207 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:mysql-metadata-storage] for class[io.druid.cli.CliCommandCreator]
2015-05-01T21:12:51,976 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/mysql-metadata-storage/0.7.1.1/mysql-metadata-storage-0.7.1.1.jar]
2015-05-01T21:12:51,987 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/mysql/mysql-connector-java/5.1.34/mysql-connector-java-5.1.34.jar]
2015-05-01T21:12:51,988 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/jdbi/jdbi/2.32/jdbi-2.32.jar]
2015-05-01T21:12:52,001 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-hdfs-storage] for class[io.druid.cli.CliCommandCreator]
2015-05-01T21:12:52,328 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/druid-hdfs-storage/0.7.1.1/druid-hdfs-storage-0.7.1.1.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.12/jackson-core-asl-1.9.12.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.12/jackson-mapper-asl-1.9.12.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2/httpclient-4.2.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2/httpcore-4.2.jar]
2015-05-01T21:12:52,329 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.4.1/hadoop-client-2.4.1.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.4.1/hadoop-common-2.4.1.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar]
2015-05-01T21:12:52,330 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.1/hadoop-auth-2.4.1.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.1/jsr305-2.0.1.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.1/hadoop-hdfs-2.4.1.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.1/hadoop-mapreduce-client-app-2.4.1.jar]
2015-05-01T21:12:52,331 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.1/hadoop-mapreduce-client-common-2.4.1.jar]
2015-05-01T21:12:52,332 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.1/hadoop-yarn-client-2.4.1.jar]
2015-05-01T21:12:52,333 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar]
2015-05-01T21:12:52,334 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.1/hadoop-yarn-server-common-2.4.1.jar]
2015-05-01T21:12:52,334 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.1/hadoop-mapreduce-client-shuffle-2.4.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.1/hadoop-yarn-api-2.4.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.1/hadoop-mapreduce-client-core-2.4.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.1/hadoop-yarn-common-2.4.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/sun/jersey/jersey-core/1.17.1/jersey-core-1.17.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.1/hadoop-mapreduce-client-jobclient-2.4.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.1/hadoop-annotations-2.4.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/metamx/emitter/0.3.0/emitter-0.3.0.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/metamx/http-client/1.0.1/http-client-1.0.1.jar]
2015-05-01T21:12:52,336 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/netty/netty/3.9.5.Final/netty-3.9.5.Final.jar]
2015-05-01T21:12:52,337 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar]
2015-05-01T21:12:52,337 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar]
2015-05-01T21:12:52,337 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar]
2015-05-01T21:12:52,337 INFO [main] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-io/commons-io/2.0.1/commons-io-2.0.1.jar]
2015-05-01T21:12:52,775 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-examples] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:52,778 INFO [main] io.druid.initialization.Initialization - Adding extension module[class io.druid.examples.ExamplesDruidModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:52,778 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-kafka-eight] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:52,780 INFO [main] io.druid.initialization.Initialization - Adding extension module[class io.druid.firehose.kafka.KafkaEightDruidModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:52,780 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:mysql-metadata-storage] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:52,783 INFO [main] io.druid.initialization.Initialization - Adding extension module[class io.druid.metadata.storage.mysql.MySQLMetadataStorageModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:52,783 INFO [main] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-hdfs-storage] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:52,784 INFO [main] io.druid.initialization.Initialization - Adding extension module[class io.druid.storage.hdfs.HdfsStorageDruidModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:12:54,370 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.metrics.DruidMonitorSchedulerConfig] from props[druid.monitoring.] as [io.druid.server.metrics.DruidMonitorSchedulerConfig@6f124533]
2015-05-01T21:12:54,431 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.metrics.MonitorsConfig] from props[druid.monitoring.] as [MonitorsConfig{monitors=[]}]
2015-05-01T21:12:54,478 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.DruidNode] from props[druid.] as [DruidNode{serviceName='overlord', host='druid-example', port=8100}]
2015-05-01T21:12:54,525 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.initialization.ServerConfig] from props[druid.server.http.] as [ServerConfig{numThreads=40, maxIdleTime=PT5M}]
2015-05-01T21:12:54,536 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.indexing.common.config.TaskConfig] from props[druid.indexer.task.] as [io.druid.indexing.common.config.TaskConfig@54bb02da]
2015-05-01T21:12:54,544 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.guice.http.DruidHttpClientConfig] from props[druid.global.http.] as [io.druid.guice.http.DruidHttpClientConfig@6fa699e1]
2015-05-01T21:12:54,699 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.client.indexing.IndexingServiceSelectorConfig] from props[druid.selectors.indexing.] as [io.druid.client.indexing.IndexingServiceSelectorConfig@752122d7]
2015-05-01T21:12:54,705 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.curator.CuratorConfig] from props[druid.zk.service.] as [io.druid.curator.CuratorConfig@3ea07b48]
2015-05-01T21:12:54,721 WARN [main] org.apache.curator.retry.ExponentialBackoffRetry - maxRetries too large (30). Pinning to 29
2015-05-01T21:12:54,800 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.initialization.CuratorDiscoveryConfig] from props[druid.discovery.curator.] as [io.druid.server.initialization.CuratorDiscoveryConfig@79115865]
2015-05-01T21:12:55,156 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.indexing.common.RetryPolicyConfig] from props[druid.peon.taskActionClient.retry.] as [io.druid.indexing.common.RetryPolicyConfig@334c3ee7]
2015-05-01T21:12:55,158 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.storage.hdfs.HdfsDataSegmentPusherConfig] from props[druid.storage.] as [io.druid.storage.hdfs.HdfsDataSegmentPusherConfig@32844cb3]
2015-05-01T21:12:55,185 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.client.DruidServerConfig] from props[druid.server.] as [io.druid.client.DruidServerConfig@40be59d2]
2015-05-01T21:12:55,192 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.initialization.BatchDataSegmentAnnouncerConfig] from props[druid.announcer.] as [io.druid.server.initialization.BatchDataSegmentAnnouncerConfig@75908eeb]
2015-05-01T21:12:55,214 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.initialization.ZkPathsConfig] from props[druid.zk.paths.] as [io.druid.server.initialization.ZkPathsConfig@58d3f4be]
2015-05-01T21:12:55,225 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[interface io.druid.server.coordination.DataSegmentAnnouncerProvider] from props[druid.announcer.] as [io.druid.server.coordination.BatchDataSegmentAnnouncerProvider@675e803]
2015-05-01T21:12:55,230 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[interface io.druid.client.FilteredServerViewProvider] from props[druid.announcer.] as [io.druid.client.FilteredBatchServerViewProvider@5267c249]
2015-05-01T21:12:55,248 INFO [main] org.skife.config.ConfigurationObjectFactory - Assigning value [67108864] for [druid.computation.buffer.size] on [io.druid.query.DruidProcessingConfig#intermediateComputeSizeBytes()]
2015-05-01T21:12:55,257 INFO [main] org.skife.config.ConfigurationObjectFactory - Assigning value [1] for [druid.processing.numThreads] on [io.druid.query.DruidProcessingConfig#getNumThreads()]
2015-05-01T21:12:55,257 INFO [main] org.skife.config.ConfigurationObjectFactory - Using method itself for [${base_path}.columnCache.sizeBytes] on [io.druid.query.DruidProcessingConfig#columnCacheSizeBytes()]
2015-05-01T21:12:55,266 INFO [main] org.skife.config.ConfigurationObjectFactory - Assigning default value [processing-%s] for [${base_path}.formatString] on [com.metamx.common.concurrent.ExecutorServiceConfig#getFormatString()]
2015-05-01T21:12:55,417 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.query.search.search.SearchQueryConfig] from props[druid.query.search.] as [io.druid.query.search.search.SearchQueryConfig@7a94eda6]
2015-05-01T21:12:55,429 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.query.groupby.GroupByQueryConfig] from props[druid.query.groupBy.] as [io.druid.query.groupby.GroupByQueryConfig@2dbb1780]
2015-05-01T21:12:55,439 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.query.topn.TopNQueryConfig] from props[druid.query.topN.] as [io.druid.query.topn.TopNQueryConfig@2166f93f]
2015-05-01T21:12:55,445 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[interface io.druid.server.log.RequestLoggerProvider] from props[druid.request.logging.] as [io.druid.server.log.NoopRequestLoggerProvider@7e585076]
2015-05-01T21:12:55,466 INFO [main] org.eclipse.jetty.util.log - Logging initialized @10062ms
2015-05-01T21:12:55,726 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void com.metamx.emitter.service.ServiceEmitter.start()] on object[com.metamx.emitter.service.ServiceEmitter@52bb1b26].
2015-05-01T21:12:55,726 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void com.metamx.metrics.MonitorScheduler.start()] on object[com.metamx.metrics.MonitorScheduler@79f38638].
2015-05-01T21:12:55,729 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void com.metamx.http.client.NettyHttpClient.start()] on object[com.metamx.http.client.NettyHttpClient@2867e48c].
2015-05-01T21:12:55,730 INFO [main] io.druid.curator.CuratorModule - Starting Curator
2015-05-01T21:12:55,730 INFO [main] org.apache.curator.framework.imps.CuratorFrameworkImpl - Starting
2015-05-01T21:12:55,749 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:host.name=druid-example
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_79
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=config/overlord:config/_common:lib/maven-model-builder-3.1.1.jar:lib/maven-repository-metadata-3.1.1.jar:lib/maven-settings-3.1.1.jar:lib/maven-settings-builder-3.1.1.jar:lib/maxminddb-0.2.0.jar:lib/mx4j-3.0.2.jar:lib/netty-3.9.5.Final.jar:lib/okhttp-1.0.2.jar:lib/opencsv-2.3.jar:lib/org.abego.treelayout.core-1.0.1.jar:lib/plexus-interpolation-1.19.jar:lib/plexus-utils-3.0.15.jar:lib/protobuf-java-2.5.0.jar:lib/rhino-1.7R5.jar:lib/RoaringBitmap-0.4.5.jar:lib/server-metrics-0.1.0.jar:lib/slf4j-api-1.6.4.jar:lib/spymemcached-2.11.4.jar:lib/tesla-aether-0.0.5.jar:lib/validation-api-1.1.0.Final.jar:lib/wagon-provider-api-2.4.jar:lib/xpp3-1.1.4c.jar:lib/zookeeper-3.4.6.jar:lib/activation-1.1.1.jar:lib/aether-api-0.9.0.M2.jar:lib/aether-connector-file-0.9.0.M2.jar:lib/aether-connector-okhttp-0.0.9.jar:lib/aether-impl-0.9.0.M2.jar:lib/aether-spi-0.9.0.M2.jar:lib/aether-util-0.9.0.M2.jar:lib/airline-0.6.jar:lib/antlr4-runtime-4.0.jar:lib/aopalliance-1.0.jar:lib/asm-3.1.jar:lib/aws-java-sdk-1.8.11.jar:lib/aws-java-sdk-core-1.8.11.jar:lib/bcprov-jdk15on-1.51.jar:lib/bytebuffer-collections-0.1.5.jar:lib/classmate-1.0.0.jar:lib/commons-cli-1.2.jar:lib/commons-codec-1.7.jar:lib/commons-dbcp2-2.0.1.jar:lib/commons-io-2.0.1.jar:lib/commons-lang-2.6.jar:lib/commons-logging-1.1.1.jar:lib/commons-pool-1.6.jar:lib/commons-pool2-2.2.jar:lib/compress-lzf-1.0.3.jar:lib/config-magic-0.9.jar:lib/curator-client-2.7.0.jar:lib/curator-framework-2.7.0.jar:lib/curator-recipes-2.7.0.jar:lib/curator-x-discovery-2.7.0.jar:lib/derby-10.11.1.1.jar:lib/derbyclient-10.11.1.1.jar:lib/derbynet-10.11.1.1.jar:lib/disruptor-3.3.0.jar:lib/druid-api-0.3.5.jar:lib/druid-aws-common-0.7.1.1.jar:lib/druid-common-0.7.1.1.jar:lib/druid-indexing-hadoop-0.7.1.1.jar:lib/druid-indexing-service-0.7.1.1.jar:lib/druid-processing-0.7.1.1.jar:lib/druid-server-0.7.1.1.jar:lib/druid-services-0.7.1.1.jar:lib/emitter-0.3.0.jar:lib/extendedset-1.3.8.jar:lib/geoip2-0.4.0.jar:lib/google-http-client-1.15.0-rc.jar:lib/google-http-client-jackson2-1.15.0-rc.jar:lib/guava-16.0.1.jar:lib/guice-4.0-beta.jar:lib/guice-multibindings-4.0-beta.jar:lib/guice-servlet-4.0-beta.jar:lib/hibernate-validator-5.1.3.Final.jar:lib/http-client-1.0.1.jar:lib/httpclient-4.2.jar:lib/httpcore-4.2.jar:lib/icu4j-4.8.1.jar:lib/irc-api-1.0-0011.jar:lib/jackson-annotations-2.4.4.jar:lib/jackson-core-2.4.4.jar:lib/jackson-core-asl-1.9.12.jar:lib/jackson-databind-2.4.4.jar:lib/jackson-dataformat-smile-2.4.4.jar:lib/jackson-datatype-guava-2.4.4.jar:lib/jackson-datatype-joda-2.4.4.jar:lib/jackson-jaxrs-base-2.4.4.jar:lib/jackson-jaxrs-json-provider-2.4.4.jar:lib/jackson-jaxrs-smile-provider-2.4.4.jar:lib/jackson-mapper-asl-1.9.13.jar:lib/jackson-module-jaxb-annotations-2.4.4.jar:lib/java-util-0.26.15.jar:lib/java-xmlbuilder-0.4.jar:lib/javax.el-3.0.0.jar:lib/javax.el-api-3.0.0.jar:lib/javax.inject-1.jar:lib/javax.servlet-api-3.1.0.jar:lib/jboss-logging-3.1.3.GA.jar:lib/jcl-over-slf4j-1.7.10.jar:lib/jdbi-2.32.jar:lib/jersey-core-1.17.1.jar:lib/jersey-guice-1.17.1.jar:lib/jersey-server-1.17.1.jar:lib/jersey-servlet-1.17.1.jar:lib/jets3t-0.9.3.jar:lib/jetty-client-9.2.5.v20141112.jar:lib/jetty-continuation-9.2.5.v20141112.jar:lib/jetty-http-9.2.5.v20141112.jar:lib/jetty-io-9.2.5.v20141112.jar:lib/jetty-proxy-9.2.5.v20141112.jar:lib/jetty-security-9.2.5.v20141112.jar:lib/jetty-server-9.2.5.v20141112.jar:lib/jetty-servlet-9.2.5.v20141112.jar:lib/jetty-servlets-9.2.5.v20141112.jar:lib/jetty-util-9.2.5.v20141112.jar:lib/jline-0.9.94.jar:lib/joda-time-2.6.jar:lib/jsr305-2.0.1.jar:lib/log4j-1.2-api-2.2.jar:lib/log4j-api-2.2.jar:lib/log4j-core-2.2.jar:lib/log4j-jul-2.2.jar:lib/log4j-slf4j-impl-2.2.jar:lib/lz4-1.3.0.jar:lib/mail-1.4.7.jar:lib/mapdb-1.0.7.jar:lib/maven-aether-provider-3.1.1.jar:lib/maven-model-3.1.1.jar:../hadoop_from_altiscale/*
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.16.0-23-generic
2015-05-01T21:12:55,750 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:user.name=root
2015-05-01T21:12:55,751 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:user.home=/root
2015-05-01T21:12:55,751 INFO [main] org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/srv/druid/druid-0.7.1.1
2015-05-01T21:12:55,752 INFO [main] org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@304806d3
2015-05-01T21:12:55,794 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void io.druid.curator.discovery.ServerDiscoverySelector.start() throws java.lang.Exception] on object[io.druid.curator.discovery.ServerDiscoverySelector@68a14ca2].
2015-05-01T21:12:55,797 INFO [main-SendThread(localhost:2181)] org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-01T21:12:55,803 INFO [main-SendThread(localhost:2181)] org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-05-01T21:12:55,819 INFO [main-SendThread(localhost:2181)] org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14d10b13f500012, negotiated timeout = 30000
2015-05-01T21:12:55,827 INFO [main-EventThread] org.apache.curator.framework.state.ConnectionStateManager - State change: CONNECTED
2015-05-01T21:12:57,014 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void io.druid.curator.announcement.Announcer.start()] on object[io.druid.curator.announcement.Announcer@62f3782].
2015-05-01T21:12:57,017 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void io.druid.client.ServerInventoryView.start() throws java.lang.Exception] on object[io.druid.client.BatchServerInventoryView@681230eb].
2015-05-01T21:12:57,034 INFO [main] org.eclipse.jetty.server.Server - jetty-9.2.5.v20141112
2015-05-01T21:12:57,175 INFO [ServerInventoryView-0] io.druid.curator.inventory.CuratorInventoryManager - Created new InventoryCacheListener for /druid/segments/druid-example:8083
2015-05-01T21:12:57,177 INFO [ServerInventoryView-0] io.druid.client.BatchServerInventoryView - New Server[DruidServerMetadata{name='druid-example:8083', host='druid-example:8083', maxSize=10000000000, tier='_default_tier', type='historical', priority='0'}]
2015-05-01T21:12:57,189 INFO [ServerInventoryView-0] io.druid.client.BatchServerInventoryView - Inventory Initialized
May 01, 2015 9:12:57 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering com.fasterxml.jackson.jaxrs.json.JacksonJsonProvider as a provider class
May 01, 2015 9:12:57 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering io.druid.server.StatusResource as a root resource class
May 01, 2015 9:12:57 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.17.1 02/28/2013 12:47 PM'
May 01, 2015 9:12:57 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding com.fasterxml.jackson.jaxrs.json.JacksonJsonProvider to GuiceManagedComponentProvider with the scope "Singleton"
May 01, 2015 9:12:58 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding io.druid.server.QueryResource to GuiceInstantiatedComponentProvider
May 01, 2015 9:12:58 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding io.druid.segment.realtime.firehose.ChatHandlerResource to GuiceInstantiatedComponentProvider
May 01, 2015 9:12:58 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding io.druid.server.StatusResource to GuiceManagedComponentProvider with the scope "Undefined"
2015-05-01T21:12:58,195 INFO [main] org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@67626254{/,null,AVAILABLE}
2015-05-01T21:12:58,206 INFO [main] org.eclipse.jetty.server.ServerConnector - Started ServerConnector@d33b7e9{HTTP/1.1}{0.0.0.0:8100}
2015-05-01T21:12:58,206 INFO [main] org.eclipse.jetty.server.Server - Started @12807ms
2015-05-01T21:12:58,206 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void io.druid.server.coordination.AbstractDataSegmentAnnouncer.start()] on object[io.druid.server.coordination.BatchDataSegmentAnnouncer@73dd7be1].
2015-05-01T21:12:58,206 INFO [main] io.druid.server.coordination.AbstractDataSegmentAnnouncer - Announcing self[DruidServerMetadata{name='druid-example:8100', host='druid-example:8100', maxSize=0, tier='_default_tier', type='indexer-executor', priority='0'}] at [/druid/announcements/druid-example:8100]
2015-05-01T21:12:58,266 INFO [ServerInventoryView-0] io.druid.curator.inventory.CuratorInventoryManager - Created new InventoryCacheListener for /druid/segments/druid-example:8100
2015-05-01T21:12:58,266 INFO [ServerInventoryView-0] io.druid.client.BatchServerInventoryView - New Server[DruidServerMetadata{name='druid-example:8100', host='druid-example:8100', maxSize=0, tier='_default_tier', type='indexer-executor', priority='0'}]
2015-05-01T21:12:58,269 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking start method[public void io.druid.indexing.worker.executor.ExecutorLifecycle.start()] on object[io.druid.indexing.worker.executor.ExecutorLifecycle@15188d22].
2015-05-01T21:12:58,477 INFO [main] io.druid.guice.PropertiesModule - Loading properties from common.runtime.properties
2015-05-01T21:12:58,479 INFO [main] io.druid.guice.PropertiesModule - Loading properties from runtime.properties
2015-05-01T21:12:58,525 INFO [main] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.guice.ExtensionsConfig] from props[druid.extensions.] as [ExtensionsConfig{searchCurrentClassloader=true, coordinates=[io.druid.extensions:druid-examples, io.druid.extensions:druid-kafka-eight, io.druid.extensions:mysql-metadata-storage, io.druid.extensions:druid-hdfs-storage], defaultVersion='0.7.1.1', localRepository='/root/.m2/repository', remoteRepositories=[https://repo1.maven.org/maven2/, https://metamx.artifactoryonline.com/metamx/pub-libs-releases-local]}]
2015-05-01T21:12:58,576 INFO [main] io.druid.indexing.worker.executor.ExecutorLifecycle - Running with task: {
  "type" : "index_hadoop",
  "id" : "index_hadoop_fastly_2015-05-01T21:12:45.336Z",
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : null
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : null,
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  },
  "hadoopDependencyCoordinates" : null,
  "classpathPrefix" : null,
  "groupId" : "index_hadoop_fastly_2015-05-01T21:12:45.336Z",
  "dataSource" : "fastly",
  "resource" : {
    "availabilityGroup" : "index_hadoop_fastly_2015-05-01T21:12:45.336Z",
    "requiredCapacity" : 1
  }
}
2015-05-01T21:12:58,587 INFO [task-runner-0] io.druid.indexing.overlord.ThreadPoolTaskRunner - Running task: index_hadoop_fastly_2015-05-01T21:12:45.336Z
2015-05-01T21:12:59,302 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.4.1/hadoop-client-2.4.1.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.4.1/hadoop-common-2.4.1.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar]
2015-05-01T21:12:59,306 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar]
2015-05-01T21:12:59,307 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar]
2015-05-01T21:12:59,315 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar]
2015-05-01T21:12:59,315 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar]
2015-05-01T21:12:59,316 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar]
2015-05-01T21:12:59,316 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar]
2015-05-01T21:12:59,316 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.1/hadoop-auth-2.4.1.jar]
2015-05-01T21:12:59,316 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar]
2015-05-01T21:12:59,316 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2.5/httpcore-4.2.5.jar]
2015-05-01T21:12:59,317 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar]
2015-05-01T21:12:59,317 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar]
2015-05-01T21:12:59,325 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar]
2015-05-01T21:12:59,325 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.1/hadoop-hdfs-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.1/hadoop-mapreduce-client-app-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.1/hadoop-mapreduce-client-common-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.1/hadoop-yarn-client-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.1/hadoop-yarn-server-common-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.1/hadoop-mapreduce-client-shuffle-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.1/hadoop-yarn-api-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.1/hadoop-mapreduce-client-core-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.1/hadoop-yarn-common-2.4.1.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar]
2015-05-01T21:12:59,326 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar]
2015-05-01T21:12:59,327 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar]
2015-05-01T21:12:59,327 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar]
2015-05-01T21:12:59,327 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar]
2015-05-01T21:12:59,327 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.1/hadoop-mapreduce-client-jobclient-2.4.1.jar]
2015-05-01T21:12:59,335 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.1/hadoop-annotations-2.4.1.jar]
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/srv/druid/druid-0.7.1.1/lib/log4j-slf4j-impl-2.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
2015-05-01T21:13:01,240 INFO [task-runner-0] io.druid.guice.PropertiesModule - Loading properties from common.runtime.properties
2015-05-01T21:13:01,247 INFO [task-runner-0] io.druid.guice.PropertiesModule - Loading properties from runtime.properties
2015-05-01T21:13:01,309 INFO [task-runner-0] org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.1.3.Final
2015-05-01T21:13:02,700 INFO [task-runner-0] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.guice.ExtensionsConfig] from props[druid.extensions.] as [ExtensionsConfig{searchCurrentClassloader=true, coordinates=[io.druid.extensions:druid-examples, io.druid.extensions:druid-kafka-eight, io.druid.extensions:mysql-metadata-storage, io.druid.extensions:druid-hdfs-storage], defaultVersion='0.7.1.1', localRepository='/root/.m2/repository', remoteRepositories=[https://repo1.maven.org/maven2/, https://metamx.artifactoryonline.com/metamx/pub-libs-releases-local]}]
2015-05-01T21:13:03,006 INFO [task-runner-0] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-examples] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:04,647 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/druid-examples/0.7.1.1/druid-examples-0.7.1.1.jar]
2015-05-01T21:13:04,647 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/twitter4j/twitter4j-core/3.0.3/twitter4j-core-3.0.3.jar]
2015-05-01T21:13:04,647 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/twitter4j/twitter4j-async/3.0.3/twitter4j-async-3.0.3.jar]
2015-05-01T21:13:04,647 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/twitter4j/twitter4j-stream/3.0.3/twitter4j-stream-3.0.3.jar]
2015-05-01T21:13:04,647 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-validator/commons-validator/1.4.0/commons-validator-1.4.0.jar]
2015-05-01T21:13:04,648 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils/1.8.3/commons-beanutils-1.8.3.jar]
2015-05-01T21:13:04,648 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar]
2015-05-01T21:13:04,648 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar]
2015-05-01T21:13:04,682 INFO [task-runner-0] io.druid.initialization.Initialization - Adding extension module[class io.druid.examples.ExamplesDruidModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:04,683 INFO [task-runner-0] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-kafka-eight] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:04,833 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/druid-kafka-eight/0.7.1.1/druid-kafka-eight-0.7.1.1.jar]
2015-05-01T21:13:04,836 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar]
2015-05-01T21:13:04,836 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar]
2015-05-01T21:13:04,836 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar]
2015-05-01T21:13:04,836 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.1/kafka-clients-0.8.2.1.jar]
2015-05-01T21:13:04,837 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar]
2015-05-01T21:13:04,837 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.6/snappy-java-1.1.1.6.jar]
2015-05-01T21:13:04,837 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar]
2015-05-01T21:13:04,838 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar]
2015-05-01T21:13:04,838 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/log4j/log4j/1.2.16/log4j-1.2.16.jar]
2015-05-01T21:13:04,838 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar]
2015-05-01T21:13:04,838 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar]
2015-05-01T21:13:04,838 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar]
2015-05-01T21:13:04,839 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar]
2015-05-01T21:13:04,870 INFO [task-runner-0] io.druid.initialization.Initialization - Adding extension module[class io.druid.firehose.kafka.KafkaEightDruidModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:04,871 INFO [task-runner-0] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:mysql-metadata-storage] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:05,332 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/mysql-metadata-storage/0.7.1.1/mysql-metadata-storage-0.7.1.1.jar]
2015-05-01T21:13:05,332 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/mysql/mysql-connector-java/5.1.34/mysql-connector-java-5.1.34.jar]
2015-05-01T21:13:05,332 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/jdbi/jdbi/2.32/jdbi-2.32.jar]
2015-05-01T21:13:05,335 INFO [task-runner-0] io.druid.initialization.Initialization - Adding extension module[class io.druid.metadata.storage.mysql.MySQLMetadataStorageModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:05,336 INFO [task-runner-0] io.druid.initialization.Initialization - Loading extension[io.druid.extensions:druid-hdfs-storage] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:05,652 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/druid/extensions/druid-hdfs-storage/0.7.1.1/druid-hdfs-storage-0.7.1.1.jar]
2015-05-01T21:13:05,652 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.12/jackson-core-asl-1.9.12.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.12/jackson-mapper-asl-1.9.12.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar]
2015-05-01T21:13:05,653 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2/httpclient-4.2.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2/httpcore-4.2.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.4.1/hadoop-client-2.4.1.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.4.1/hadoop-common-2.4.1.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar]
2015-05-01T21:13:05,654 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar]
2015-05-01T21:13:05,655 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar]
2015-05-01T21:13:05,656 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar]
2015-05-01T21:13:05,656 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.1/hadoop-auth-2.4.1.jar]
2015-05-01T21:13:05,656 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.1/jsr305-2.0.1.jar]
2015-05-01T21:13:05,656 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar]
2015-05-01T21:13:05,656 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar]
2015-05-01T21:13:05,656 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar]
2015-05-01T21:13:05,656 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.1/hadoop-hdfs-2.4.1.jar]
2015-05-01T21:13:05,657 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar]
2015-05-01T21:13:05,657 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.1/hadoop-mapreduce-client-app-2.4.1.jar]
2015-05-01T21:13:05,657 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.1/hadoop-mapreduce-client-common-2.4.1.jar]
2015-05-01T21:13:05,657 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.1/hadoop-yarn-client-2.4.1.jar]
2015-05-01T21:13:05,657 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar]
2015-05-01T21:13:05,657 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.1/hadoop-yarn-server-common-2.4.1.jar]
2015-05-01T21:13:05,657 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.1/hadoop-mapreduce-client-shuffle-2.4.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.1/hadoop-yarn-api-2.4.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.1/hadoop-mapreduce-client-core-2.4.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.1/hadoop-yarn-common-2.4.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/sun/jersey/jersey-core/1.17.1/jersey-core-1.17.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.1/hadoop-mapreduce-client-jobclient-2.4.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.1/hadoop-annotations-2.4.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/metamx/emitter/0.3.0/emitter-0.3.0.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/metamx/http-client/1.0.1/http-client-1.0.1.jar]
2015-05-01T21:13:05,658 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/io/netty/netty/3.9.5.Final/netty-3.9.5.Final.jar]
2015-05-01T21:13:05,659 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar]
2015-05-01T21:13:05,659 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar]
2015-05-01T21:13:05,659 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar]
2015-05-01T21:13:05,659 INFO [task-runner-0] io.druid.initialization.Initialization - Added URL[file:/root/.m2/repository/commons-io/commons-io/2.0.1/commons-io-2.0.1.jar]
2015-05-01T21:13:05,665 INFO [task-runner-0] io.druid.initialization.Initialization - Adding extension module[class io.druid.storage.hdfs.HdfsStorageDruidModule] for class[io.druid.initialization.DruidModule]
2015-05-01T21:13:06,660 INFO [task-runner-0] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.metrics.DruidMonitorSchedulerConfig] from props[druid.monitoring.] as [io.druid.server.metrics.DruidMonitorSchedulerConfig@6fd88c7f]
2015-05-01T21:13:06,671 INFO [task-runner-0] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.server.metrics.MonitorsConfig] from props[druid.monitoring.] as [MonitorsConfig{monitors=[]}]
2015-05-01T21:13:06,894 INFO [task-runner-0] io.druid.guice.PropertiesModule - Loading properties from common.runtime.properties
2015-05-01T21:13:06,896 INFO [task-runner-0] io.druid.guice.PropertiesModule - Loading properties from runtime.properties
2015-05-01T21:13:06,917 INFO [task-runner-0] io.druid.guice.JsonConfigurator - Loaded class[class io.druid.guice.ExtensionsConfig] from props[druid.extensions.] as [ExtensionsConfig{searchCurrentClassloader=true, coordinates=[io.druid.extensions:druid-examples, io.druid.extensions:druid-kafka-eight, io.druid.extensions:mysql-metadata-storage, io.druid.extensions:druid-hdfs-storage], defaultVersion='0.7.1.1', localRepository='/root/.m2/repository', remoteRepositories=[https://repo1.maven.org/maven2/, https://metamx.artifactoryonline.com/metamx/pub-libs-releases-local]}]
2015-05-01T21:13:06,917 INFO [task-runner-0] io.druid.indexing.common.task.HadoopIndexTask - Starting a hadoop determine configuration job...
2015-05-01T21:13:07,679 WARN [task-runner-0] org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-05-01T21:13:07,707 INFO [task-runner-0] io.druid.indexer.path.StaticPathSpec - Adding paths[hdfs://localhost:8020/user/rustyp/logs]
2015-05-01T21:13:08,935 INFO [task-runner-0] io.druid.indexer.path.StaticPathSpec - Adding paths[hdfs://localhost:8020/user/rustyp/logs]
2015-05-01T21:13:09,012 INFO [task-runner-0] org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
2015-05-01T21:13:09,014 INFO [task-runner-0] org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
2015-05-01T21:13:09,058 WARN [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-05-01T21:13:09,061 WARN [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-05-01T21:13:09,725 INFO [task-runner-0] org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 8
2015-05-01T21:13:09,780 INFO [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - number of splits:8
2015-05-01T21:13:09,962 INFO [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local587427708_0001
2015-05-01T21:13:10,025 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/staging/rustyp587427708/.staging/job_local587427708_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-05-01T21:13:10,032 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/staging/rustyp587427708/.staging/job_local587427708_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-05-01T21:13:10,225 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/local/localRunner/rustyp/job_local587427708_0001/job_local587427708_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-05-01T21:13:10,232 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/local/localRunner/rustyp/job_local587427708_0001/job_local587427708_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-05-01T21:13:10,296 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2015-05-01T21:13:10,296 INFO [task-runner-0] io.druid.indexer.DetermineHashedPartitionsJob - Job fastly-determine_partitions_hashed-Optional.absent() submitted, status available at: http://localhost:8080/
2015-05-01T21:13:10,299 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Running job: job_local587427708_0001
2015-05-01T21:13:10,304 INFO [Thread-53] org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2015-05-01T21:13:10,386 INFO [Thread-53] org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-05-01T21:13:10,518 INFO [Thread-53] org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2015-05-01T21:13:10,518 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000000_0
2015-05-01T21:13:10,584 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:10,592 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-HbZdesmWKmN0uA8AAAAA.log:0+1766
2015-05-01T21:13:10,610 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:10,738 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:10,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:10,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:10,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:10,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:10,867 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:10,868 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:11,304 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Job job_local587427708_0001 running in uber mode : false
2015-05-01T21:13:11,306 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2015-05-01T21:13:11,324 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:11,329 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:11,329 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:11,329 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 28; bufvoid = 104857600
2015-05-01T21:13:11,329 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:11,335 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:11,336 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000000_0 is done. And is in the process of committing
2015-05-01T21:13:11,354 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:11,354 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000000_0' done.
2015-05-01T21:13:11,355 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000000_0
2015-05-01T21:13:11,355 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000001_0
2015-05-01T21:13:11,355 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:11,356 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-g8QnDzAtvfmQjBAAAAAA.log:0+1323
2015-05-01T21:13:11,356 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:11,492 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:11,492 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:11,492 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:11,492 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:11,492 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:11,580 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:11,583 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:11,755 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:11,755 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:11,755 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:11,755 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 25; bufvoid = 104857600
2015-05-01T21:13:11,755 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:11,757 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:11,758 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000001_0 is done. And is in the process of committing
2015-05-01T21:13:11,759 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:11,759 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000001_0' done.
2015-05-01T21:13:11,759 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000001_0
2015-05-01T21:13:11,759 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000002_0
2015-05-01T21:13:11,760 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:11,761 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-MnS0fupBuDoavWYAAAAA.log:0+880
2015-05-01T21:13:11,762 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:11,897 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:11,897 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:11,897 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:11,897 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:11,897 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:12,001 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:12,004 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:12,175 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:12,176 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:12,176 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:12,176 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 25; bufvoid = 104857600
2015-05-01T21:13:12,176 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:12,177 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:12,179 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000002_0 is done. And is in the process of committing
2015-05-01T21:13:12,180 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:12,180 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000002_0' done.
2015-05-01T21:13:12,180 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000002_0
2015-05-01T21:13:12,180 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000003_0
2015-05-01T21:13:12,181 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:12,182 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-vI6Rk76D_60d7vcAAAAA.log:0+880
2015-05-01T21:13:12,182 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:12,320 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2015-05-01T21:13:12,333 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:12,334 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:12,334 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:12,334 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:12,334 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:12,421 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:12,424 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:12,668 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:12,668 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:12,668 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:12,668 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 25; bufvoid = 104857600
2015-05-01T21:13:12,668 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:12,669 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:12,673 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000003_0 is done. And is in the process of committing
2015-05-01T21:13:12,674 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:12,674 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000003_0' done.
2015-05-01T21:13:12,674 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000003_0
2015-05-01T21:13:12,675 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000004_0
2015-05-01T21:13:12,676 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:12,677 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-oGmBj3qd9kZjtJ8AAAAA.log:0+810
2015-05-01T21:13:12,677 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:12,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:12,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:12,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:12,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:12,807 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:12,897 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:12,899 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:13,070 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:13,070 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:13,070 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:13,070 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 25; bufvoid = 104857600
2015-05-01T21:13:13,070 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:13,072 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:13,073 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000004_0 is done. And is in the process of committing
2015-05-01T21:13:13,074 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:13,074 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000004_0' done.
2015-05-01T21:13:13,074 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000004_0
2015-05-01T21:13:13,074 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000005_0
2015-05-01T21:13:13,075 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:13,075 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-kVRAVHftknQUTO0AAAAA.log:0+441
2015-05-01T21:13:13,076 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:13,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:13,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:13,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:13,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:13,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:13,315 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:13,322 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:13,454 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:13,454 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:13,454 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:13,454 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 22; bufvoid = 104857600
2015-05-01T21:13:13,454 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:13,455 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:13,460 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000005_0 is done. And is in the process of committing
2015-05-01T21:13:13,463 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:13,464 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000005_0' done.
2015-05-01T21:13:13,464 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000005_0
2015-05-01T21:13:13,464 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000006_0
2015-05-01T21:13:13,464 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:13,465 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-Q7l-rFo3Ufr1Wo0AAAAA.log:0+440
2015-05-01T21:13:13,465 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:13,597 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:13,597 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:13,597 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:13,597 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:13,597 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:13,697 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:13,700 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:13,870 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:13,870 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:13,870 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:13,870 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 22; bufvoid = 104857600
2015-05-01T21:13:13,870 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:13,871 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:13,877 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000006_0 is done. And is in the process of committing
2015-05-01T21:13:13,878 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:13,878 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000006_0' done.
2015-05-01T21:13:13,878 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000006_0
2015-05-01T21:13:13,878 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_m_000007_0
2015-05-01T21:13:13,879 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:13,880 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-jOY5mpNv_dWq7okAAAAA.log:0+440
2015-05-01T21:13:13,880 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:14,014 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:14,014 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:14,014 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:14,014 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:14,014 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:14,112 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:14,114 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:14,289 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:14,290 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:14,290 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:14,290 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 22; bufvoid = 104857600
2015-05-01T21:13:14,290 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:14,291 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:14,292 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_m_000007_0 is done. And is in the process of committing
2015-05-01T21:13:14,293 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:14,294 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_m_000007_0' done.
2015-05-01T21:13:14,294 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_m_000007_0
2015-05-01T21:13:14,294 INFO [Thread-53] org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2015-05-01T21:13:14,297 INFO [Thread-53] org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2015-05-01T21:13:14,298 INFO [pool-23-thread-1] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local587427708_0001_r_000000_0
2015-05-01T21:13:14,310 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:14,317 INFO [pool-23-thread-1] org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32aec01e
2015-05-01T21:13:14,339 INFO [pool-23-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=702441024, maxSingleShuffleLimit=175610256, mergeThreshold=463611104, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2015-05-01T21:13:14,344 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local587427708_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2015-05-01T21:13:14,384 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000002_0 decomp: 29 len: 33 to MEMORY
2015-05-01T21:13:14,389 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 29 bytes from map-output for attempt_local587427708_0001_m_000002_0
2015-05-01T21:13:14,395 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 29, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->29
2015-05-01T21:13:14,396 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000001_0 decomp: 29 len: 33 to MEMORY
2015-05-01T21:13:14,396 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 29 bytes from map-output for attempt_local587427708_0001_m_000001_0
2015-05-01T21:13:14,396 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 29, inMemoryMapOutputs.size() -> 2, commitMemory -> 29, usedMemory ->58
2015-05-01T21:13:14,397 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000005_0 decomp: 26 len: 30 to MEMORY
2015-05-01T21:13:14,397 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 26 bytes from map-output for attempt_local587427708_0001_m_000005_0
2015-05-01T21:13:14,397 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 26, inMemoryMapOutputs.size() -> 3, commitMemory -> 58, usedMemory ->84
2015-05-01T21:13:14,398 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000006_0 decomp: 26 len: 30 to MEMORY
2015-05-01T21:13:14,398 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 26 bytes from map-output for attempt_local587427708_0001_m_000006_0
2015-05-01T21:13:14,398 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 26, inMemoryMapOutputs.size() -> 4, commitMemory -> 84, usedMemory ->110
2015-05-01T21:13:14,399 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000004_0 decomp: 29 len: 33 to MEMORY
2015-05-01T21:13:14,400 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 29 bytes from map-output for attempt_local587427708_0001_m_000004_0
2015-05-01T21:13:14,400 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 29, inMemoryMapOutputs.size() -> 5, commitMemory -> 110, usedMemory ->139
2015-05-01T21:13:14,400 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000007_0 decomp: 26 len: 30 to MEMORY
2015-05-01T21:13:14,401 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 26 bytes from map-output for attempt_local587427708_0001_m_000007_0
2015-05-01T21:13:14,401 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 26, inMemoryMapOutputs.size() -> 6, commitMemory -> 139, usedMemory ->165
2015-05-01T21:13:14,402 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000000_0 decomp: 32 len: 36 to MEMORY
2015-05-01T21:13:14,402 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 32 bytes from map-output for attempt_local587427708_0001_m_000000_0
2015-05-01T21:13:14,402 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 7, commitMemory -> 165, usedMemory ->197
2015-05-01T21:13:14,403 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local587427708_0001_m_000003_0 decomp: 29 len: 33 to MEMORY
2015-05-01T21:13:14,403 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 29 bytes from map-output for attempt_local587427708_0001_m_000003_0
2015-05-01T21:13:14,403 INFO [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 29, inMemoryMapOutputs.size() -> 8, commitMemory -> 197, usedMemory ->226
2015-05-01T21:13:14,403 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2015-05-01T21:13:14,404 INFO [pool-23-thread-1] org.apache.hadoop.mapred.LocalJobRunner - 8 / 8 copied.
2015-05-01T21:13:14,404 INFO [pool-23-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 8 in-memory map-outputs and 0 on-disk map-outputs
2015-05-01T21:13:14,414 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Merger - Merging 8 sorted segments
2015-05-01T21:13:14,414 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 8 segments left of total size: 146 bytes
2015-05-01T21:13:14,415 INFO [pool-23-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 8 segments, 226 bytes to disk to satisfy reduce memory limit
2015-05-01T21:13:14,415 INFO [pool-23-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 216 bytes from disk
2015-05-01T21:13:14,416 INFO [pool-23-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2015-05-01T21:13:14,416 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2015-05-01T21:13:14,417 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 202 bytes
2015-05-01T21:13:14,417 INFO [pool-23-thread-1] org.apache.hadoop.mapred.LocalJobRunner - 8 / 8 copied.
2015-05-01T21:13:14,454 INFO [pool-23-thread-1] org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2015-05-01T21:13:14,462 INFO [pool-23-thread-1] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : null
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:12:45.336Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : { },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:14,499 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Task - Task:attempt_local587427708_0001_r_000000_0 is done. And is in the process of committing
2015-05-01T21:13:14,502 INFO [pool-23-thread-1] org.apache.hadoop.mapred.LocalJobRunner - 8 / 8 copied.
2015-05-01T21:13:14,502 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Task - Task attempt_local587427708_0001_r_000000_0 is allowed to commit now
2015-05-01T21:13:14,503 INFO [pool-23-thread-1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local587427708_0001_r_000000_0' to file:/tmp/druid-indexing/fastly/2015-05-01T211245.336Z/groupedData/_temporary/0/task_local587427708_0001_r_000000
2015-05-01T21:13:14,503 INFO [pool-23-thread-1] org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2015-05-01T21:13:14,503 INFO [pool-23-thread-1] org.apache.hadoop.mapred.Task - Task 'attempt_local587427708_0001_r_000000_0' done.
2015-05-01T21:13:14,503 INFO [pool-23-thread-1] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local587427708_0001_r_000000_0
2015-05-01T21:13:14,503 INFO [Thread-53] org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2015-05-01T21:13:15,321 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2015-05-01T21:13:15,322 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Job job_local587427708_0001 completed successfully
2015-05-01T21:13:15,348 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Counters: 38
	File System Counters
		FILE: Number of bytes read=53935
		FILE: Number of bytes written=2045559
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=45932
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=8
		Map output bytes=194
		Map output materialized bytes=258
		Input split bytes=1216
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=258
		Reduce input records=8
		Reduce output records=0
		Spilled Records=16
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=968
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1831858176
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6980
	File Output Format Counters 
		Bytes Written=106
2015-05-01T21:13:15,348 INFO [task-runner-0] io.druid.indexer.DetermineHashedPartitionsJob - Job completed, loading up partitions for intervals[Optional.absent()].
2015-05-01T21:13:15,369 INFO [task-runner-0] io.druid.indexer.DetermineHashedPartitionsJob - Determined Intervals for Job [%s]Optional.of([2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z])
2015-05-01T21:13:15,370 INFO [task-runner-0] io.druid.indexer.DetermineHashedPartitionsJob - Found approximately [14] rows in data.
2015-05-01T21:13:15,370 INFO [task-runner-0] io.druid.indexer.DetermineHashedPartitionsJob - Creating [1] shards
2015-05-01T21:13:15,371 INFO [task-runner-0] io.druid.indexer.DetermineHashedPartitionsJob - DetermineHashedPartitionsJob took 6661 millis
2015-05-01T21:13:15,371 INFO [task-runner-0] io.druid.indexer.JobHelper - Deleting path[/tmp/druid-indexing/fastly/2015-05-01T211245.336Z]
2015-05-01T21:13:15,438 INFO [task-runner-0] io.druid.indexing.common.actions.RemoteTaskActionClient - Performing action for task[index_hadoop_fastly_2015-05-01T21:12:45.336Z]: LockAcquireAction{interval=2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z}
2015-05-01T21:13:15,450 INFO [task-runner-0] io.druid.indexing.common.actions.RemoteTaskActionClient - Submitting action for task[index_hadoop_fastly_2015-05-01T21:12:45.336Z] to overlord[http://druid-example:8090/druid/indexer/v1/action]: LockAcquireAction{interval=2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z}
2015-05-01T21:13:15,476 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,551 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,551 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,552 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,552 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,552 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,553 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,553 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,554 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,561 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,562 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,562 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,563 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,563 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,568 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,568 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,569 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,571 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,572 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,573 INFO [task-runner-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating: http://druid-example:8090
2015-05-01T21:13:15,661 INFO [task-runner-0] io.druid.indexing.common.task.HadoopIndexTask - Setting version to: 2015-05-01T21:13:15.611Z
2015-05-01T21:13:15,717 INFO [task-runner-0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:15,717 INFO [task-runner-0] io.druid.indexing.common.task.HadoopIndexTask - Starting a hadoop index generator job...
2015-05-01T21:13:15,740 INFO [task-runner-0] io.druid.indexer.path.StaticPathSpec - Adding paths[hdfs://localhost:8020/user/rustyp/logs]
2015-05-01T21:13:15,742 INFO [task-runner-0] io.druid.indexer.HadoopDruidIndexerJob - No metadataStorageUpdaterJob set in the config. This is cool if you are running a hadoop index task, otherwise nothing will be uploaded to database.
2015-05-01T21:13:15,806 INFO [task-runner-0] io.druid.indexer.path.StaticPathSpec - Adding paths[hdfs://localhost:8020/user/rustyp/logs]
2015-05-01T21:13:15,808 INFO [task-runner-0] org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2015-05-01T21:13:15,813 WARN [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-05-01T21:13:15,817 WARN [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-05-01T21:13:16,154 INFO [task-runner-0] org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 8
2015-05-01T21:13:16,168 INFO [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - number of splits:8
2015-05-01T21:13:16,278 INFO [task-runner-0] org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local313922873_0002
2015-05-01T21:13:16,339 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/staging/rustyp313922873/.staging/job_local313922873_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-05-01T21:13:16,339 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/staging/rustyp313922873/.staging/job_local313922873_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-05-01T21:13:16,451 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/local/localRunner/rustyp/job_local313922873_0002/job_local313922873_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-05-01T21:13:16,452 WARN [task-runner-0] org.apache.hadoop.conf.Configuration - file:/tmp/hadoop-root/mapred/local/localRunner/rustyp/job_local313922873_0002/job_local313922873_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-05-01T21:13:16,453 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2015-05-01T21:13:16,453 INFO [task-runner-0] io.druid.indexer.IndexGeneratorJob - Job fastly-index-generator-Optional.of([2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z]) submitted, status available at http://localhost:8080/
2015-05-01T21:13:16,453 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Running job: job_local313922873_0002
2015-05-01T21:13:16,453 INFO [Thread-83] org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2015-05-01T21:13:16,454 INFO [Thread-83] org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-05-01T21:13:16,456 INFO [Thread-83] org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2015-05-01T21:13:16,456 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000000_0
2015-05-01T21:13:16,457 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:16,457 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-HbZdesmWKmN0uA8AAAAA.log:0+1766
2015-05-01T21:13:16,460 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:16,598 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:16,598 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:16,598 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:16,598 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:16,598 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:16,687 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:16,855 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:16,855 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:16,855 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:16,855 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1966; bufvoid = 104857600
2015-05-01T21:13:16,855 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
2015-05-01T21:13:16,856 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:16,858 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000000_0 is done. And is in the process of committing
2015-05-01T21:13:16,859 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:16,859 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000000_0' done.
2015-05-01T21:13:16,859 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000000_0
2015-05-01T21:13:16,860 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000001_0
2015-05-01T21:13:16,860 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:16,861 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-g8QnDzAtvfmQjBAAAAAA.log:0+1323
2015-05-01T21:13:16,861 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:16,989 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:16,989 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:16,989 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:16,989 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:16,989 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:17,085 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:17,260 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:17,260 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:17,260 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:17,260 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1473; bufvoid = 104857600
2015-05-01T21:13:17,260 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2015-05-01T21:13:17,261 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:17,262 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000001_0 is done. And is in the process of committing
2015-05-01T21:13:17,264 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:17,264 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000001_0' done.
2015-05-01T21:13:17,264 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000001_0
2015-05-01T21:13:17,265 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000002_0
2015-05-01T21:13:17,266 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:17,266 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-MnS0fupBuDoavWYAAAAA.log:0+880
2015-05-01T21:13:17,267 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:17,394 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:17,395 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:17,395 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:17,395 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:17,395 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:17,453 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Job job_local313922873_0002 running in uber mode : false
2015-05-01T21:13:17,453 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2015-05-01T21:13:17,601 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:17,808 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:17,808 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:17,808 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:17,808 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 980; bufvoid = 104857600
2015-05-01T21:13:17,808 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2015-05-01T21:13:17,810 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:17,811 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000002_0 is done. And is in the process of committing
2015-05-01T21:13:17,813 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:17,813 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000002_0' done.
2015-05-01T21:13:17,813 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000002_0
2015-05-01T21:13:17,813 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000003_0
2015-05-01T21:13:17,814 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:17,815 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-vI6Rk76D_60d7vcAAAAA.log:0+880
2015-05-01T21:13:17,816 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:17,955 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:17,955 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:17,955 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:17,955 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:17,955 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:18,044 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:18,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:18,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:18,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:18,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 980; bufvoid = 104857600
2015-05-01T21:13:18,216 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2015-05-01T21:13:18,217 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:18,218 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000003_0 is done. And is in the process of committing
2015-05-01T21:13:18,225 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:18,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000003_0' done.
2015-05-01T21:13:18,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000003_0
2015-05-01T21:13:18,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000004_0
2015-05-01T21:13:18,226 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:18,227 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-oGmBj3qd9kZjtJ8AAAAA.log:0+810
2015-05-01T21:13:18,227 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:18,360 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:18,360 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:18,360 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:18,360 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:18,360 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:18,449 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:18,540 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:18,540 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:18,540 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:18,540 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 910; bufvoid = 104857600
2015-05-01T21:13:18,540 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2015-05-01T21:13:18,541 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:18,542 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000004_0 is done. And is in the process of committing
2015-05-01T21:13:18,543 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:18,544 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000004_0' done.
2015-05-01T21:13:18,544 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000004_0
2015-05-01T21:13:18,544 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000005_0
2015-05-01T21:13:18,544 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:18,545 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-kVRAVHftknQUTO0AAAAA.log:0+441
2015-05-01T21:13:18,545 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:18,669 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:18,669 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:18,669 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:18,669 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:18,669 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:18,759 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:18,929 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:18,929 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:18,929 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:18,930 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 491; bufvoid = 104857600
2015-05-01T21:13:18,930 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:18,930 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:18,931 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000005_0 is done. And is in the process of committing
2015-05-01T21:13:18,932 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:18,932 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000005_0' done.
2015-05-01T21:13:18,933 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000005_0
2015-05-01T21:13:18,933 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000006_0
2015-05-01T21:13:18,934 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:18,934 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-Q7l-rFo3Ufr1Wo0AAAAA.log:0+440
2015-05-01T21:13:18,934 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:19,063 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:19,063 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:19,063 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:19,063 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:19,063 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:19,155 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:19,339 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:19,340 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:19,340 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:19,340 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 490; bufvoid = 104857600
2015-05-01T21:13:19,340 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:19,341 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:19,342 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000006_0 is done. And is in the process of committing
2015-05-01T21:13:19,343 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:19,343 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000006_0' done.
2015-05-01T21:13:19,343 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000006_0
2015-05-01T21:13:19,343 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_m_000007_0
2015-05-01T21:13:19,344 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:19,345 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:8020/user/rustyp/logs/2015-05-01T18-25-00.000-jOY5mpNv_dWq7okAAAAA.log:0+440
2015-05-01T21:13:19,345 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-05-01T21:13:19,477 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2015-05-01T21:13:19,477 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2015-05-01T21:13:19,477 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2015-05-01T21:13:19,477 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2015-05-01T21:13:19,477 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2015-05-01T21:13:19,569 INFO [LocalJobRunner Map Task Executor #0] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:19,738 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - 
2015-05-01T21:13:19,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Starting flush of map output
2015-05-01T21:13:19,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Spilling map output
2015-05-01T21:13:19,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 490; bufvoid = 104857600
2015-05-01T21:13:19,739 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-05-01T21:13:19,740 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.MapTask - Finished spill 0
2015-05-01T21:13:19,741 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_m_000007_0 is done. And is in the process of committing
2015-05-01T21:13:19,742 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - map
2015-05-01T21:13:19,742 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_m_000007_0' done.
2015-05-01T21:13:19,743 INFO [LocalJobRunner Map Task Executor #0] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_m_000007_0
2015-05-01T21:13:19,743 INFO [Thread-83] org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2015-05-01T21:13:19,743 INFO [Thread-83] org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2015-05-01T21:13:19,743 INFO [pool-26-thread-1] org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local313922873_0002_r_000000_0
2015-05-01T21:13:19,744 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2015-05-01T21:13:19,744 INFO [pool-26-thread-1] org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69f34ccb
2015-05-01T21:13:19,745 INFO [pool-26-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=702441024, maxSingleShuffleLimit=175610256, mergeThreshold=463611104, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2015-05-01T21:13:19,745 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local313922873_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2015-05-01T21:13:19,746 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000004_0 decomp: 920 len: 924 to MEMORY
2015-05-01T21:13:19,746 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 920 bytes from map-output for attempt_local313922873_0002_m_000004_0
2015-05-01T21:13:19,746 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 920, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->920
2015-05-01T21:13:19,747 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000001_0 decomp: 1487 len: 1491 to MEMORY
2015-05-01T21:13:19,747 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1487 bytes from map-output for attempt_local313922873_0002_m_000001_0
2015-05-01T21:13:19,747 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1487, inMemoryMapOutputs.size() -> 2, commitMemory -> 920, usedMemory ->2407
2015-05-01T21:13:19,748 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000007_0 decomp: 496 len: 500 to MEMORY
2015-05-01T21:13:19,748 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 496 bytes from map-output for attempt_local313922873_0002_m_000007_0
2015-05-01T21:13:19,749 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 496, inMemoryMapOutputs.size() -> 3, commitMemory -> 2407, usedMemory ->2903
2015-05-01T21:13:19,749 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000000_0 decomp: 1984 len: 1988 to MEMORY
2015-05-01T21:13:19,749 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1984 bytes from map-output for attempt_local313922873_0002_m_000000_0
2015-05-01T21:13:19,750 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1984, inMemoryMapOutputs.size() -> 4, commitMemory -> 2903, usedMemory ->4887
2015-05-01T21:13:19,752 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000003_0 decomp: 990 len: 994 to MEMORY
2015-05-01T21:13:19,752 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 990 bytes from map-output for attempt_local313922873_0002_m_000003_0
2015-05-01T21:13:19,752 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 990, inMemoryMapOutputs.size() -> 5, commitMemory -> 4887, usedMemory ->5877
2015-05-01T21:13:19,753 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000006_0 decomp: 496 len: 500 to MEMORY
2015-05-01T21:13:19,753 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 496 bytes from map-output for attempt_local313922873_0002_m_000006_0
2015-05-01T21:13:19,753 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 496, inMemoryMapOutputs.size() -> 6, commitMemory -> 5877, usedMemory ->6373
2015-05-01T21:13:19,754 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000005_0 decomp: 497 len: 501 to MEMORY
2015-05-01T21:13:19,754 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 497 bytes from map-output for attempt_local313922873_0002_m_000005_0
2015-05-01T21:13:19,754 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 497, inMemoryMapOutputs.size() -> 7, commitMemory -> 6373, usedMemory ->6870
2015-05-01T21:13:19,755 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local313922873_0002_m_000002_0 decomp: 990 len: 994 to MEMORY
2015-05-01T21:13:19,755 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 990 bytes from map-output for attempt_local313922873_0002_m_000002_0
2015-05-01T21:13:19,755 INFO [localfetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 990, inMemoryMapOutputs.size() -> 8, commitMemory -> 6870, usedMemory ->7860
2015-05-01T21:13:19,755 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2015-05-01T21:13:19,756 INFO [pool-26-thread-1] org.apache.hadoop.mapred.LocalJobRunner - 8 / 8 copied.
2015-05-01T21:13:19,756 INFO [pool-26-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 8 in-memory map-outputs and 0 on-disk map-outputs
2015-05-01T21:13:19,757 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Merger - Merging 8 sorted segments
2015-05-01T21:13:19,757 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 8 segments left of total size: 7444 bytes
2015-05-01T21:13:19,758 INFO [pool-26-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 8 segments, 7860 bytes to disk to satisfy reduce memory limit
2015-05-01T21:13:19,758 INFO [pool-26-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7850 bytes from disk
2015-05-01T21:13:19,758 INFO [pool-26-thread-1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2015-05-01T21:13:19,758 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2015-05-01T21:13:19,758 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7794 bytes
2015-05-01T21:13:19,758 INFO [pool-26-thread-1] org.apache.hadoop.mapred.LocalJobRunner - 8 / 8 copied.
2015-05-01T21:13:19,772 INFO [pool-26-thread-1] io.druid.indexer.HadoopDruidIndexerConfig - Running with config:
{
  "spec" : {
    "dataSchema" : {
      "dataSource" : "fastly",
      "parser" : {
        "type" : "string",
        "parseSpec" : {
          "format" : "tsv",
          "timestampSpec" : {
            "column" : "timestamp",
            "format" : "EEE, dd MMM yyyy HH:mm:ss z"
          },
          "dimensionsSpec" : {
            "dimensions" : [ "area_code", "campaignid", "city", "clientid", "continent_code", "cookie", "country_code", "country_code3", "country_name", "fingerprint", "ipaddress", "latitude", "longitude", "metro_code", "postal_code", "region", "requesttype", "start", "statuscode", "timestamp", "url" ],
            "dimensionExclusions" : [ "added", "delta", "deleted" ],
            "spatialDimensions" : [ {
              "dimName" : "coordinates",
              "dims" : [ "latitude", "longitude" ]
            } ]
          },
          "delimiter" : "|",
          "listDelimiter" : null,
          "columns" : [ "start", "timestamp", "ipaddress", "cookie", "url", "requesttype", "statuscode", "latitude", "longitude", "city", "continent_code", "country_code", "country_code3", "country_name", "postal_code", "region", "area_code", "metro_code", "fingerprint", "clientid", "campaignid" ]
        }
      },
      "metricsSpec" : [ {
        "type" : "count",
        "name" : "count"
      }, {
        "type" : "doubleSum",
        "name" : "added",
        "fieldName" : "added"
      }, {
        "type" : "doubleSum",
        "name" : "deleted",
        "fieldName" : "deleted"
      }, {
        "type" : "doubleSum",
        "name" : "delta",
        "fieldName" : "delta"
      } ],
      "granularitySpec" : {
        "type" : "uniform",
        "segmentGranularity" : "DAY",
        "queryGranularity" : {
          "type" : "none"
        },
        "intervals" : [ "2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z" ]
      }
    },
    "ioConfig" : {
      "type" : "hadoop",
      "inputSpec" : {
        "type" : "static",
        "paths" : "hdfs://localhost:8020/user/rustyp/logs"
      },
      "metadataUpdateSpec" : null,
      "segmentOutputPath" : "hdfs://127.0.0.1:8020/user/rustyp/druid/fastly"
    },
    "tuningConfig" : {
      "type" : "hadoop",
      "workingPath" : "/tmp/druid-indexing",
      "version" : "2015-05-01T21:13:15.611Z",
      "partitionsSpec" : {
        "type" : "hashed",
        "targetPartitionSize" : 5000000,
        "maxPartitionSize" : 7500000,
        "assumeGrouped" : false,
        "numShards" : -1
      },
      "shardSpecs" : {
        "2015-05-01T00:00:00.000Z" : [ {
          "actualSpec" : {
            "type" : "none"
          },
          "shardNum" : 0
        } ]
      },
      "leaveIntermediate" : false,
      "cleanupOnFailure" : true,
      "overwriteFiles" : false,
      "ignoreInvalidRows" : false,
      "jobProperties" : { },
      "combineText" : false,
      "persistInHeap" : false,
      "ingestOffheap" : false,
      "bufferSize" : 134217728,
      "aggregationBufferRatio" : 0.5,
      "rowFlushBoundary" : 80000
    }
  }
}
2015-05-01T21:13:19,835 INFO [pool-26-thread-1] io.druid.indexer.IndexGeneratorJob - 16 lines completed.
2015-05-01T21:13:19,846 INFO [pool-26-thread-1] io.druid.guice.PropertiesModule - Loading properties from common.runtime.properties
2015-05-01T21:13:19,848 INFO [pool-26-thread-1] io.druid.guice.PropertiesModule - Loading properties from runtime.properties
2015-05-01T21:13:19,875 INFO [pool-26-thread-1] io.druid.guice.JsonConfigurator - Loaded class[interface io.druid.segment.data.BitmapSerdeFactory] from props[druid.processing.bitmap.] as [io.druid.segment.data.BitmapSerde$DefaultBitmapSerdeFactory@5421637c]
2015-05-01T21:13:19,875 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting persist for interval[2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z], rows[14]
2015-05-01T21:13:19,919 INFO [pool-26-thread-1] io.druid.guice.PropertiesModule - Loading properties from common.runtime.properties
2015-05-01T21:13:19,920 INFO [pool-26-thread-1] io.druid.guice.PropertiesModule - Loading properties from runtime.properties
2015-05-01T21:13:19,933 INFO [pool-26-thread-1] org.skife.config.ConfigurationObjectFactory - Assigning value [67108864] for [druid.computation.buffer.size] on [io.druid.query.DruidProcessingConfig#intermediateComputeSizeBytes()]
2015-05-01T21:13:19,938 INFO [pool-26-thread-1] org.skife.config.ConfigurationObjectFactory - Assigning value [1] for [druid.processing.numThreads] on [io.druid.query.DruidProcessingConfig#getNumThreads()]
2015-05-01T21:13:19,939 INFO [pool-26-thread-1] org.skife.config.ConfigurationObjectFactory - Using method itself for [${base_path}.columnCache.sizeBytes] on [io.druid.query.DruidProcessingConfig#columnCacheSizeBytes()]
2015-05-01T21:13:19,941 INFO [pool-26-thread-1] org.skife.config.ConfigurationObjectFactory - Assigning default value [processing-%s] for [${base_path}.formatString] on [com.metamx.common.concurrent.ExecutorServiceConfig#getFormatString()]
2015-05-01T21:13:20,046 INFO [pool-26-thread-1] io.druid.guice.JsonConfigurator - Loaded class[interface io.druid.segment.data.BitmapSerdeFactory] from props[druid.processing.bitmap.] as [io.druid.segment.data.BitmapSerde$DefaultBitmapSerdeFactory@4a7836aa]
2015-05-01T21:13:20,047 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - outDir[/tmp/base9191681325558178278flush/merged/v8-tmp] completed index.drd in 141 millis.
2015-05-01T21:13:20,112 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - outDir[/tmp/base9191681325558178278flush/merged/v8-tmp] completed dim conversions in 65 millis.
2015-05-01T21:13:20,230 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - outDir[/tmp/base9191681325558178278flush/merged/v8-tmp] completed walk through of 14 rows in 118 millis.
2015-05-01T21:13:20,231 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[area_code] with cardinality[1]
2015-05-01T21:13:20,244 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[area_code] in 14 millis.
2015-05-01T21:13:20,244 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[campaignid] with cardinality[2]
2015-05-01T21:13:20,245 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[campaignid] in 1 millis.
2015-05-01T21:13:20,245 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[city] with cardinality[1]
2015-05-01T21:13:20,246 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[city] in 1 millis.
2015-05-01T21:13:20,246 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[clientid] with cardinality[2]
2015-05-01T21:13:20,247 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[clientid] in 1 millis.
2015-05-01T21:13:20,247 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[continent_code] with cardinality[1]
2015-05-01T21:13:20,247 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[continent_code] in 0 millis.
2015-05-01T21:13:20,248 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[cookie] with cardinality[1]
2015-05-01T21:13:20,248 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[cookie] in 0 millis.
2015-05-01T21:13:20,255 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[coordinates] with cardinality[2]
2015-05-01T21:13:20,274 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[coordinates] in 26 millis.
2015-05-01T21:13:20,281 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[country_code] with cardinality[1]
2015-05-01T21:13:20,281 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[country_code] in 0 millis.
2015-05-01T21:13:20,282 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[country_code3] with cardinality[1]
2015-05-01T21:13:20,282 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[country_code3] in 0 millis.
2015-05-01T21:13:20,283 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[country_name] with cardinality[1]
2015-05-01T21:13:20,290 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[country_name] in 7 millis.
2015-05-01T21:13:20,290 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[fingerprint] with cardinality[1]
2015-05-01T21:13:20,293 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[fingerprint] in 2 millis.
2015-05-01T21:13:20,293 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[ipaddress] with cardinality[1]
2015-05-01T21:13:20,294 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[ipaddress] in 1 millis.
2015-05-01T21:13:20,294 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[metro_code] with cardinality[1]
2015-05-01T21:13:20,295 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[metro_code] in 1 millis.
2015-05-01T21:13:20,295 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[postal_code] with cardinality[1]
2015-05-01T21:13:20,296 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[postal_code] in 1 millis.
2015-05-01T21:13:20,296 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[region] with cardinality[1]
2015-05-01T21:13:20,297 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[region] in 1 millis.
2015-05-01T21:13:20,298 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[requesttype] with cardinality[4]
2015-05-01T21:13:20,299 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[requesttype] in 2 millis.
2015-05-01T21:13:20,299 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[start] with cardinality[14]
2015-05-01T21:13:20,300 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[start] in 1 millis.
2015-05-01T21:13:20,300 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[statuscode] with cardinality[1]
2015-05-01T21:13:20,301 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[statuscode] in 1 millis.
2015-05-01T21:13:20,301 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[timestamp] with cardinality[9]
2015-05-01T21:13:20,302 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[timestamp] in 1 millis.
2015-05-01T21:13:20,304 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Starting dimension[url] with cardinality[1]
2015-05-01T21:13:20,305 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - Completed dimension[url] in 2 millis.
2015-05-01T21:13:20,305 INFO [pool-26-thread-1] io.druid.segment.IndexMerger - outDir[/tmp/base9191681325558178278flush/merged/v8-tmp] completed inverted.drd in 75 millis.
2015-05-01T21:13:20,320 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Converting v8[/tmp/base9191681325558178278flush/merged/v8-tmp] to v9[/tmp/base9191681325558178278flush/merged]
2015-05-01T21:13:20,335 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_area_code.drd]
2015-05-01T21:13:20,339 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[area_code] is single value, converting...
2015-05-01T21:13:20,349 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_campaignid.drd]
2015-05-01T21:13:20,349 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[campaignid] is single value, converting...
2015-05-01T21:13:20,350 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_city.drd]
2015-05-01T21:13:20,350 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[city] is single value, converting...
2015-05-01T21:13:20,350 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_clientid.drd]
2015-05-01T21:13:20,350 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[clientid] is single value, converting...
2015-05-01T21:13:20,350 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_continent_code.drd]
2015-05-01T21:13:20,350 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[continent_code] is single value, converting...
2015-05-01T21:13:20,351 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_cookie.drd]
2015-05-01T21:13:20,351 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[cookie] is single value, converting...
2015-05-01T21:13:20,351 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_coordinates.drd]
2015-05-01T21:13:20,351 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[coordinates] is single value, converting...
2015-05-01T21:13:20,352 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_country_code.drd]
2015-05-01T21:13:20,352 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[country_code] is single value, converting...
2015-05-01T21:13:20,352 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_country_code3.drd]
2015-05-01T21:13:20,352 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[country_code3] is single value, converting...
2015-05-01T21:13:20,352 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_country_name.drd]
2015-05-01T21:13:20,352 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[country_name] is single value, converting...
2015-05-01T21:13:20,353 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_fingerprint.drd]
2015-05-01T21:13:20,353 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[fingerprint] is single value, converting...
2015-05-01T21:13:20,353 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_ipaddress.drd]
2015-05-01T21:13:20,353 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[ipaddress] is single value, converting...
2015-05-01T21:13:20,355 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_metro_code.drd]
2015-05-01T21:13:20,356 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[metro_code] is single value, converting...
2015-05-01T21:13:20,356 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_postal_code.drd]
2015-05-01T21:13:20,356 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[postal_code] is single value, converting...
2015-05-01T21:13:20,356 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_region.drd]
2015-05-01T21:13:20,356 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[region] is single value, converting...
2015-05-01T21:13:20,357 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_requesttype.drd]
2015-05-01T21:13:20,359 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[requesttype] is single value, converting...
2015-05-01T21:13:20,360 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_start.drd]
2015-05-01T21:13:20,361 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[start] is single value, converting...
2015-05-01T21:13:20,361 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_statuscode.drd]
2015-05-01T21:13:20,361 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[statuscode] is single value, converting...
2015-05-01T21:13:20,361 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_timestamp.drd]
2015-05-01T21:13:20,361 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[timestamp] is single value, converting...
2015-05-01T21:13:20,362 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[dim_url.drd]
2015-05-01T21:13:20,362 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Dimension[url] is single value, converting...
2015-05-01T21:13:20,362 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[index.drd]
2015-05-01T21:13:20,362 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[inverted.drd]
2015-05-01T21:13:20,362 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[met_added_LITTLE_ENDIAN.drd]
2015-05-01T21:13:20,369 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[met_count_LITTLE_ENDIAN.drd]
2015-05-01T21:13:20,369 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[met_deleted_LITTLE_ENDIAN.drd]
2015-05-01T21:13:20,370 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[met_delta_LITTLE_ENDIAN.drd]
2015-05-01T21:13:20,370 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[spatial.drd]
2015-05-01T21:13:20,370 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Processing file[time_LITTLE_ENDIAN.drd]
2015-05-01T21:13:20,375 INFO [pool-26-thread-1] io.druid.segment.IndexIO$DefaultIndexIOHandler - Skipped files[[index.drd, inverted.drd, spatial.drd]]
2015-05-01T21:13:20,851 INFO [pool-26-thread-1] io.druid.indexer.IndexGeneratorJob - Creating new ZipEntry[00000.smoosh]
2015-05-01T21:13:20,852 INFO [pool-26-thread-1] io.druid.indexer.IndexGeneratorJob - Creating new ZipEntry[meta.smoosh]
2015-05-01T21:13:20,852 INFO [pool-26-thread-1] io.druid.indexer.IndexGeneratorJob - Creating new ZipEntry[version.bin]
2015-05-01T21:13:23,779 INFO [pool-26-thread-1] io.druid.indexer.IndexGeneratorJob - Writing descriptor to path[/tmp/druid-indexing/fastly/2015-05-01T211315.611Z/segmentDescriptorInfo/fastly_2015-05-01T000000.000Z_2015-05-02T000000.000Z_2015-05-01T211315.611Z.json]
2015-05-01T21:13:23,781 INFO [pool-26-thread-1] io.druid.indexer.IndexGeneratorJob - Successfully renamed [hdfs://127.0.0.1:8020/user/rustyp/druid/fastly/fastly/20150501T000000.000Z_20150502T000000.000Z/2015-05-01T21_13_15.611Z/0/index.zip.0] to [hdfs://127.0.0.1:8020/user/rustyp/druid/fastly/fastly/20150501T000000.000Z_20150502T000000.000Z/2015-05-01T21_13_15.611Z/0/index.zip]
2015-05-01T21:13:23,782 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Task - Task:attempt_local313922873_0002_r_000000_0 is done. And is in the process of committing
2015-05-01T21:13:23,783 INFO [pool-26-thread-1] org.apache.hadoop.mapred.LocalJobRunner - 8 / 8 copied.
2015-05-01T21:13:23,783 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Task - Task attempt_local313922873_0002_r_000000_0 is allowed to commit now
2015-05-01T21:13:23,783 INFO [pool-26-thread-1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local313922873_0002_r_000000_0' to file:/tmp/druid-indexing/fastly/2015-05-01T211315.611Z/_temporary/0/task_local313922873_0002_r_000000
2015-05-01T21:13:23,785 INFO [pool-26-thread-1] org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2015-05-01T21:13:23,785 INFO [pool-26-thread-1] org.apache.hadoop.mapred.Task - Task 'attempt_local313922873_0002_r_000000_0' done.
2015-05-01T21:13:23,785 INFO [pool-26-thread-1] org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local313922873_0002_r_000000_0
2015-05-01T21:13:23,785 INFO [Thread-83] org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2015-05-01T21:13:24,470 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2015-05-01T21:13:24,471 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Job job_local313922873_0002 completed successfully
2015-05-01T21:13:24,484 INFO [task-runner-0] org.apache.hadoop.mapreduce.Job - Counters: 38
	File System Counters
		FILE: Number of bytes read=149789
		FILE: Number of bytes written=4167914
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108752
		HDFS: Number of bytes written=3022
		HDFS: Number of read operations=172
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7780
		Map output materialized bytes=7892
		Input split bytes=1216
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=7892
		Reduce input records=16
		Reduce output records=0
		Spilled Records=32
		Shuffled Maps =8
		Failed Shuffles=0
		Merged Map outputs=8
		GC time elapsed (ms)=929
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1804058624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6980
	File Output Format Counters 
		Bytes Written=8
2015-05-01T21:13:24,551 INFO [task-runner-0] io.druid.indexer.IndexGeneratorJob - Adding segment fastly_2015-05-01T00:00:00.000Z_2015-05-02T00:00:00.000Z_2015-05-01T21:13:15.611Z to the list of published segments
2015-05-01T21:13:24,551 INFO [task-runner-0] io.druid.indexer.JobHelper - Deleting path[/tmp/druid-indexing/fastly/2015-05-01T211315.611Z]
2015-05-01T21:13:24,622 INFO [task-runner-0] io.druid.indexing.common.actions.RemoteTaskActionClient - Performing action for task[index_hadoop_fastly_2015-05-01T21:12:45.336Z]: SegmentInsertAction{segments=[DataSegment{size=10357, shardSpec=NoneShardSpec, metrics=[count, added, deleted, delta], dimensions=[region, continent_code, metro_code, area_code, ipaddress, country_code, url, country_name, city, timestamp, clientid, cookie, fingerprint, start, postal_code, country_code3, campaignid, statuscode, coordinates, requesttype], version='2015-05-01T21:13:15.611Z', loadSpec={type=hdfs, path=hdfs://127.0.0.1:8020/user/rustyp/druid/fastly/fastly/20150501T000000.000Z_20150502T000000.000Z/2015-05-01T21_13_15.611Z/0/index.zip}, interval=2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z, dataSource='fastly', binaryVersion='9'}]}
2015-05-01T21:13:24,632 INFO [task-runner-0] io.druid.indexing.common.actions.RemoteTaskActionClient - Submitting action for task[index_hadoop_fastly_2015-05-01T21:12:45.336Z] to overlord[http://druid-example:8090/druid/indexer/v1/action]: SegmentInsertAction{segments=[DataSegment{size=10357, shardSpec=NoneShardSpec, metrics=[count, added, deleted, delta], dimensions=[region, continent_code, metro_code, area_code, ipaddress, country_code, url, country_name, city, timestamp, clientid, cookie, fingerprint, start, postal_code, country_code3, campaignid, statuscode, coordinates, requesttype], version='2015-05-01T21:13:15.611Z', loadSpec={type=hdfs, path=hdfs://127.0.0.1:8020/user/rustyp/druid/fastly/fastly/20150501T000000.000Z_20150502T000000.000Z/2015-05-01T21_13_15.611Z/0/index.zip}, interval=2015-05-01T00:00:00.000Z/2015-05-02T00:00:00.000Z, dataSource='fastly', binaryVersion='9'}]}
2015-05-01T21:13:24,734 INFO [task-runner-0] io.druid.indexing.worker.executor.ExecutorLifecycle - Task completed with status: {
  "id" : "index_hadoop_fastly_2015-05-01T21:12:45.336Z",
  "status" : "SUCCESS",
  "duration" : 26143
}
2015-05-01T21:13:24,742 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void io.druid.server.coordination.AbstractDataSegmentAnnouncer.stop()] on object[io.druid.server.coordination.BatchDataSegmentAnnouncer@73dd7be1].
2015-05-01T21:13:24,742 INFO [main] io.druid.server.coordination.AbstractDataSegmentAnnouncer - Stopping class io.druid.server.coordination.BatchDataSegmentAnnouncer with config[io.druid.server.initialization.ZkPathsConfig@58d3f4be]
2015-05-01T21:13:24,742 INFO [main] io.druid.curator.announcement.Announcer - unannouncing [/druid/announcements/druid-example:8100]
2015-05-01T21:13:24,773 INFO [ServerInventoryView-0] io.druid.client.BatchServerInventoryView - Server Disappeared[DruidServerMetadata{name='druid-example:8100', host='druid-example:8100', maxSize=0, tier='_default_tier', type='indexer-executor', priority='0'}]
2015-05-01T21:13:24,774 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void io.druid.indexing.worker.executor.ExecutorLifecycle.stop()] on object[io.druid.indexing.worker.executor.ExecutorLifecycle@15188d22].
2015-05-01T21:13:24,780 INFO [main] org.eclipse.jetty.server.ServerConnector - Stopped ServerConnector@d33b7e9{HTTP/1.1}{0.0.0.0:8100}
2015-05-01T21:13:24,783 INFO [main] org.eclipse.jetty.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@67626254{/,null,UNAVAILABLE}
2015-05-01T21:13:24,786 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void io.druid.indexing.overlord.ThreadPoolTaskRunner.stop()] on object[io.druid.indexing.overlord.ThreadPoolTaskRunner@71c76bca].
2015-05-01T21:13:24,787 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void io.druid.client.ServerInventoryView.stop() throws java.io.IOException] on object[io.druid.client.BatchServerInventoryView@681230eb].
2015-05-01T21:13:24,787 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void io.druid.curator.announcement.Announcer.stop()] on object[io.druid.curator.announcement.Announcer@62f3782].
2015-05-01T21:13:24,787 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void io.druid.curator.discovery.ServerDiscoverySelector.stop() throws java.io.IOException] on object[io.druid.curator.discovery.ServerDiscoverySelector@68a14ca2].
2015-05-01T21:13:24,793 INFO [main] io.druid.curator.CuratorModule - Stopping Curator
2015-05-01T21:13:24,798 INFO [main-EventThread] org.apache.zookeeper.ClientCnxn - EventThread shut down
2015-05-01T21:13:24,798 INFO [main] org.apache.zookeeper.ZooKeeper - Session: 0x14d10b13f500012 closed
2015-05-01T21:13:24,798 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void com.metamx.http.client.NettyHttpClient.stop()] on object[com.metamx.http.client.NettyHttpClient@2867e48c].
2015-05-01T21:13:24,817 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void com.metamx.metrics.MonitorScheduler.stop()] on object[com.metamx.metrics.MonitorScheduler@79f38638].
2015-05-01T21:13:24,817 INFO [main] com.metamx.common.lifecycle.Lifecycle$AnnotationBasedHandler - Invoking stop method[public void com.metamx.emitter.service.ServiceEmitter.close() throws java.io.IOException] on object[com.metamx.emitter.service.ServiceEmitter@52bb1b26].
